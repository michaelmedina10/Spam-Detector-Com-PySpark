{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detector de SPAM\n",
    "\n",
    "O intuito deste projeto é desenvolver um modelo de machine learning que possua a capacidade de identificar se uma determinada\n",
    "\n",
    "mensagem é um SPAM.\n",
    "\n",
    "O termo Spam pode ser um acrónimo derivado da expressão em inglês \"Sending and Posting Advertisement in Mass\", traduzido em português \n",
    "\n",
    "\"Enviar e Postar Publicidade em Massa\", Normalmente são mensagens eletrônicas que recebemos por e-mail, SMS, Redes sociais sem o nosso \n",
    "\n",
    "consentimento.\n",
    "\n",
    "OBS: Este projeto poderia ser desenvolvido somente com pyhton, scikit-learn e NLTK, porém desta vez prefiri fazer uso do apache SPARK.\n",
    "\n",
    "DATASET retirado do site Kaggle, endereço:\n",
    "\n",
    "https://www.kaggle.com/uciml/sms-spam-collection-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports utilizados\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import IDF, HashingTF, Tokenizer, StopWordsRemover\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verificando a versão do spark\n",
    "sc.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma sessão spark session para usarmos sparkSQL\n",
    "spSession = SparkSession.builder.master(\"Local\").appName(\"SpamDetect\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['v1,v2,,,',\n",
       " 'ham,\"Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\",,,',\n",
       " 'ham,Ok lar... Joking wif u oni...,,,',\n",
       " \"spam,Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's,,,\",\n",
       " 'ham,U dun say so early hor... U c already then say...,,,']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregando os registros de SMS e mostrando as primeiras linhas \n",
    "spamdata = sc.textFile(\"spam.csv\")\n",
    "spamdata.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5575"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quantidade de registros\n",
    "spamdata.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ham,\"Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\",,,',\n",
       " 'ham,Ok lar... Joking wif u oni...,,,']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removendo o cabeçalho\n",
    "header = spamdata.first()\n",
    "spamdataRDD = spamdata.filter(lambda line : line != header)\n",
    "spamdataRDD.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5574"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spamdataRDD.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpeza e pré-processamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando o atributo que classifica se o SMS é um spam para formato numérico\n",
    "def transformWords(rdd):\n",
    "    attList = rdd.split(',')\n",
    "    smsMessage = 1.0 if attList[0] == 'spam' else 0.0\n",
    "    return [smsMessage, attList[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, '\"Go until jurong point'],\n",
       " [0.0, 'Ok lar... Joking wif u oni...'],\n",
       " [1.0,\n",
       "  \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\"],\n",
       " [0.0, 'U dun say so early hor... U c already then say...'],\n",
       " [0.0, '\"Nah I don\\'t think he goes to usf'],\n",
       " [1.0,\n",
       "  '\"FreeMsg Hey there darling it\\'s been 3 week\\'s now and no word back! I\\'d like some fun you up for it still? Tb ok! XxX std chgs to send'],\n",
       " [0.0,\n",
       "  'Even my brother is not like to speak with me. They treat me like aids patent.'],\n",
       " [0.0,\n",
       "  \"As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\"],\n",
       " [1.0,\n",
       "  'WINNER!! As a valued network customer you have been selected to receivea �900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.'],\n",
       " [1.0,\n",
       "  'Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicando a função ao RDD\n",
    "# Lembrando que uma RDD é imutável\n",
    "\n",
    "spamdataRDD2 = spamdataRDD.map(transformWords)\n",
    "spamdataRDD2.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|             message|\n",
      "+-----+--------------------+\n",
      "|  0.0|\"Go until jurong ...|\n",
      "|  0.0|Ok lar... Joking ...|\n",
      "|  1.0|Free entry in 2 a...|\n",
      "|  0.0|U dun say so earl...|\n",
      "|  0.0|\"Nah I don't thin...|\n",
      "|  1.0|\"FreeMsg Hey ther...|\n",
      "|  0.0|Even my brother i...|\n",
      "|  0.0|As per your reque...|\n",
      "|  1.0|WINNER!! As a val...|\n",
      "|  1.0|Had your mobile 1...|\n",
      "|  0.0|\"I'm gonna be hom...|\n",
      "|  1.0|\"SIX chances to w...|\n",
      "|  1.0|\"URGENT! You have...|\n",
      "|  0.0|I've been searchi...|\n",
      "|  0.0|I HAVE A DATE ON ...|\n",
      "|  1.0|\"XXXMobileMovieCl...|\n",
      "|  0.0|Oh k...i'm watchi...|\n",
      "|  0.0|Eh u remember how...|\n",
      "|  0.0|Fine if that��s t...|\n",
      "|  1.0|\"England v Macedo...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Criando um dataframe com o SparkSQL\n",
    "# Lembrando que estou usando o JDK8, pois o 11 ainda não possui suporte para trabalharmos com o modelo ANSI (Instruções SQL originais), no qual eu \n",
    "# particularmente prefiro\n",
    "\n",
    "spamDF = spSession.createDataFrame(spamdataRDD2, ['label', 'message'])\n",
    "spamDF.createOrReplaceTempView(\"tableSpam\")\n",
    "spSession.sql(\"Select label, message from tableSpam\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processamento de Linguagem natural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Como estamos lidando com linguagem verbal escrita, precisamos aplicar alguns tratamento para melhorar\n",
    "a qualidade de aprendizado do algoritmo de machine learning. Logo iremos aplicar alguns métodos de processamento de linguagem natural, como \n",
    "tokenização, remoção das stopwords e stemming.</p>\n",
    "\n",
    "<p>Vamos a algumas explicações antes, tokenização é o nome dado ao processo que se refere a separar textos em \"pedaços\", tokens, por exemplo, caso \n",
    "tenhamos um parágrafo posso tokenizar em sentenças e a partir das sentenças tokenizar em palavras.</p>\n",
    "\n",
    "<p>StopWords são aquelas palavras de um respectivo idioma no qual não agrega muito significado na sentença, pelo menos em relação a uma análise e para\n",
    "otimizar a performance do modelo normalmente as removemos. Exemplos de stopwords em português são as palavras, de, da, um, umas.</p>\n",
    "\n",
    "<p>Stemmings são os sufixos e prefixos de palavras que também removemos para otimização do modelo, o Google costuma utilizar esta técnica no momento de \n",
    "realizar as suas buscas.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|             message|\n",
      "+-----+--------------------+\n",
      "|  0.0|\"Go until jurong ...|\n",
      "|  0.0|Ok lar... Jok  wi...|\n",
      "|  1.0|Free entry in 2 a...|\n",
      "|  0.0|U dun say so earl...|\n",
      "|  0.0|\"Nah I don't thin...|\n",
      "|  1.0|\"FreeMsg Hey th e...|\n",
      "|  0.0|Even my broth  is...|\n",
      "|  0.0|As p  your requ  ...|\n",
      "|  1.0|WINNER!! As a val...|\n",
      "|  1.0|Had your mobile 1...|\n",
      "|  0.0|\"I'm gonna be hom...|\n",
      "|  1.0|\"SIX chances to w...|\n",
      "|  1.0|\"URGENT! You have...|\n",
      "|  0.0|I've been search ...|\n",
      "|  0.0|I HAVE A DATE ON ...|\n",
      "|  1.0|\"XXXMobileMovieCl...|\n",
      "|  0.0|Oh k...i'm watch ...|\n",
      "|  0.0|Eh u rememb  how ...|\n",
      "|  0.0|Fine if that��s t...|\n",
      "|  1.0|\"England v Macedo...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Removendo os stemmings das palavras\n",
    "\n",
    "spamDF2 = spamDF.select(\"label\", (regexp_replace('message', 'ing|er|ier|est', \" \")))\n",
    "spamDF2 = spamDF2.toPandas()\n",
    "spamDF3 = spSession.createDataFrame(spamDF2, ['label', 'message'])\n",
    "spamDF3.select(\"*\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HashingTF cria uma tabela com a frequencia de cada termo remanescente e o IDF cálcula estatisticamente a importância\n",
    "# de cada palavra com base na frequência criada pelo hashingTF.\n",
    "tokenizer = Tokenizer(inputCol='message', outputCol='tokenMessage')\n",
    "stopWords = StopWordsRemover(inputCol= tokenizer.getOutputCol(), outputCol= 'outStopWords')\n",
    "hashingTF = HashingTF(inputCol= stopWords.getOutputCol(), outputCol= \"hashingWords\")\n",
    "idf = IDF(inputCol=hashingTF.getOutputCol(), outputCol= \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+-------+\n",
      "|label|             message|indexed|\n",
      "+-----+--------------------+-------+\n",
      "|  0.0|\"Go until jurong ...|    0.0|\n",
      "|  0.0|Ok lar... Jok  wi...|    0.0|\n",
      "|  1.0|Free entry in 2 a...|    1.0|\n",
      "|  0.0|U dun say so earl...|    0.0|\n",
      "|  0.0|\"Nah I don't thin...|    0.0|\n",
      "|  1.0|\"FreeMsg Hey th e...|    1.0|\n",
      "|  0.0|Even my broth  is...|    0.0|\n",
      "|  0.0|As p  your requ  ...|    0.0|\n",
      "|  1.0|WINNER!! As a val...|    1.0|\n",
      "|  1.0|Had your mobile 1...|    1.0|\n",
      "|  0.0|\"I'm gonna be hom...|    0.0|\n",
      "|  1.0|\"SIX chances to w...|    1.0|\n",
      "|  1.0|\"URGENT! You have...|    1.0|\n",
      "|  0.0|I've been search ...|    0.0|\n",
      "|  0.0|I HAVE A DATE ON ...|    0.0|\n",
      "|  1.0|\"XXXMobileMovieCl...|    1.0|\n",
      "|  0.0|Oh k...i'm watch ...|    0.0|\n",
      "|  0.0|Eh u rememb  how ...|    0.0|\n",
      "|  0.0|Fine if that��s t...|    0.0|\n",
      "|  1.0|\"England v Macedo...|    1.0|\n",
      "+-----+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# String Indexer é utilizado para converter variáveis categóricas, contudo, é também um requerimento para podermos\n",
    "# testar algoritmos de ML baseado em árvores (trees).\n",
    "stringindexer = StringIndexer(inputCol= 'label', outputCol='indexed')\n",
    "si_model = stringindexer.fit(spamDF3)\n",
    "spamDF4 = si_model.transform(spamDF3)\n",
    "\n",
    "spamDF4.select(\"label\", 'message', 'indexed').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicando Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo o DataFrame em conjuntos de dados treino e teste\n",
    "dados_treino, dados_teste = spamDF4.randomSplit([0.8,0.2], seed= 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4454"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_treino.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1120"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_teste.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação dos PipeLines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Normalmente para verificação de Spams o algoritmo mais recomendado é o Naive Bayes, pois ele é rápido, simples e \n",
    "retorna a probabilidade do resultado. </p>\n",
    "\n",
    "<p>Contudo também irei testar com os modelos de árvores, como decision tree e random forest, ambos somente aceitam váriaveis do tipo numérica, como neste caso são mensagens eu usei o atributo gerado a partir do modulo IDF explicado anteriormente</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "naiveBayes = NaiveBayes()\n",
    "dcTree = DecisionTreeClassifier(maxDepth= 10, labelCol='indexed', featuresCol= 'features')\n",
    "rdforest = RandomForestClassifier(labelCol=\"indexed\", featuresCol='features', numTrees= 10)\n",
    "\n",
    "# Pipelines\n",
    "pipeDcTree = Pipeline(stages=[tokenizer, stopWords, hashingTF, idf, dcTree])\n",
    "pipeNB = Pipeline(stages=[tokenizer, stopWords, hashingTF, idf, naiveBayes])\n",
    "pipeRForest = Pipeline(stages=[tokenizer, stopWords, hashingTF, idf, rdforest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando o modelo Naive Bayes\n",
    "model = pipeNB.fit(dados_treino)\n",
    "previsoes = model.transform(dados_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando o modelo de árvore de decisão\n",
    "model1 = pipeDcTree.fit(dados_treino)\n",
    "previsoes1 = model1.transform(dados_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando o modelo Random Forest\n",
    "model2 = pipeRForest.fit(dados_treino)\n",
    "previsoes2 = model2.transform(dados_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Imprimindo os dez primeiros Registros com cada previsão realizada</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+--------------------+\n",
      "|label|prediction|             message|\n",
      "+-----+----------+--------------------+\n",
      "|  0.0|       0.0|                    |\n",
      "|  0.0|       0.0|      \"Aight will do|\n",
      "|  0.0|       0.0|        \"Alright omw|\n",
      "|  0.0|       0.0|\"Although i told ...|\n",
      "|  0.0|       0.0|            \"Awesome|\n",
      "|  0.0|       0.0|\"Beautiful Truth ...|\n",
      "|  0.0|       0.0|         \"Come to mu|\n",
      "|  0.0|       0.0|               \"Cool|\n",
      "|  0.0|       0.0|               \"Dear|\n",
      "|  0.0|       0.0|               \"Dear|\n",
      "+-----+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dez primeiras previsões do modelo Random Forest\n",
    "previsoes2.select(\"label\", \"prediction\", \"message\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+--------------------+\n",
      "|label|prediction|             message|\n",
      "+-----+----------+--------------------+\n",
      "|  0.0|       0.0|                    |\n",
      "|  0.0|       0.0|      \"Aight will do|\n",
      "|  0.0|       0.0|        \"Alright omw|\n",
      "|  0.0|       0.0|\"Although i told ...|\n",
      "|  0.0|       0.0|            \"Awesome|\n",
      "|  0.0|       0.0|\"Beautiful Truth ...|\n",
      "|  0.0|       0.0|         \"Come to mu|\n",
      "|  0.0|       0.0|               \"Cool|\n",
      "|  0.0|       0.0|               \"Dear|\n",
      "|  0.0|       0.0|               \"Dear|\n",
      "+-----+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dez primeiras previsões do modelo Decision Tree\n",
    "previsoes1.select(\"label\", \"prediction\", \"message\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+--------------------+\n",
      "|label|prediction|             message|\n",
      "+-----+----------+--------------------+\n",
      "|  0.0|       0.0|                    |\n",
      "|  0.0|       0.0|      \"Aight will do|\n",
      "|  0.0|       0.0|        \"Alright omw|\n",
      "|  0.0|       0.0|\"Although i told ...|\n",
      "|  0.0|       0.0|            \"Awesome|\n",
      "|  0.0|       0.0|\"Beautiful Truth ...|\n",
      "|  0.0|       0.0|         \"Come to mu|\n",
      "|  0.0|       0.0|               \"Cool|\n",
      "|  0.0|       0.0|               \"Dear|\n",
      "|  0.0|       0.0|               \"Dear|\n",
      "+-----+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dez primeiras previsões do modelo Naive Bayes\n",
    "previsoes.select(\"label\", \"prediction\", \"message\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando a acurácia dos algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9598214285714286\n",
      "0.9267857142857143\n",
      "0.8580357142857142\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label', metricName= 'accuracy')\n",
    "print(evaluator.evaluate(previsoes))\n",
    "\n",
    "# Decision Tree\n",
    "evaluator1 = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label', metricName= 'accuracy')\n",
    "print(evaluator1.evaluate(previsoes1))\n",
    "\n",
    "# Random Forest\n",
    "evaluator2 = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label', metricName= 'accuracy')\n",
    "print(evaluator1.evaluate(previsoes2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Podemos verificar que realmente o algoritmo Naive Bayes se sobressaiu em relação aos demais com uma taxa de acerto\n",
    "equivalente a 96% , ou seja, a cada cem mensagens ele acerta 96, é uma ótima acurácia.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|  136|\n",
      "|  0.0|       1.0|   22|\n",
      "|  1.0|       0.0|   23|\n",
      "|  0.0|       0.0|  939|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "previsoes.groupby(\"label\", 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|   85|\n",
      "|  0.0|       1.0|    8|\n",
      "|  1.0|       0.0|   74|\n",
      "|  0.0|       0.0|  953|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "previsoes1.groupby(\"label\", 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       0.0|  159|\n",
      "|  0.0|       0.0|  961|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "previsoes2.groupby(\"label\", 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com isso concluimos nosso projeto para detecção de spams com êxito."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
